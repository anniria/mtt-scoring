{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Translation\n",
    "\n",
    "The following code is employed for the purpose of automatically translating our German text data into English, utilising natural language processing. We are employing three different models for this task. \n",
    "\n",
    "Note: ChatGPT was consulted to a limited extent in the process of developing the code, mainly for trouble shooting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Housekeeping\n",
    "\n",
    "Here, we import the data and packages that we need for the translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install packages if necessary\n",
    "!pip install pandas\n",
    "!pip install transformers\n",
    "!pip install sentencepiece\n",
    "!pip install deep-translator\n",
    "!pip install sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data \n",
    "data = pd.read_csv(\"../data/raw/data.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MarianMT\n",
    "\n",
    "Translation with the model MarianMT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model that is used for translation\n",
    "marian = \"Helsinki-NLP/opus-mt-de-en\"\n",
    "model = MarianMTModel.from_pretrained(marian)\n",
    "tokenizer = MarianTokenizer.from_pretrained(marian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to tranlate text data\n",
    "def translate_marian(text):\n",
    "    # tokenize the text input \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    # generate translation \n",
    "    translated_tokens = model.generate(**inputs)\n",
    "    # decode the translated tokens into string\n",
    "    translated_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the translation function to the \"text\" column\n",
    "data['text_eng'] = data['text'].apply(translate_marian)\n",
    "\n",
    "# write data into a file \n",
    "data.to_csv(\"../data/translated/data_marian.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MBart\n",
    "\n",
    "Translation with the model MBart: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model that is used for translation\n",
    "mbart = \"facebook/mbart-large-50-many-to-many-mmt\"\n",
    "model = MBartForConditionalGeneration.from_pretrained(mbart)\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(mbart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to tranlate text data\n",
    "def translate_mbart(text):\n",
    "    tokenizer.src_lang = \"de_DE\"  \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    translated_tokens = model.generate(**inputs, forced_bos_token_id=tokenizer.lang_code_to_id[\"en_XX\"])\n",
    "    translated_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "# apply the translation function \n",
    "data['text_eng'] = data['text'].apply(translate_mbart)\n",
    "\n",
    "# write data into a file\n",
    "data.to_csv(\"../data/translated/data_mbart.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Translator\n",
    "\n",
    "Translation with Google Translator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to translate text data\n",
    "def translate_google(text):\n",
    "    translator = Translator()\n",
    "    translated = translator.translate(text, src='de', dest='en')\n",
    "    return translated.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the translation function \n",
    "data['text_eng'] = data['text'].apply(translate_google)\n",
    "\n",
    "# write data into a file\n",
    "data.to_csv(\"../data/translated/data_google.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
