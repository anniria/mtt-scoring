{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring of the Autobiographical Interview with NLP\n",
    "\n",
    "This code is used to automatically score text data using natural language processing. The trained language model of Genugten and Schacter (2024) is employed to score English text data in accordance with the Autobiographical Interview method (Levine, 2002). \n",
    "\n",
    "## License and Copyright Note\n",
    "\n",
    "The code is based on the [Colab Notebook](https://colab.research.google.com/github/rubenvangenugten/autobiographical_interview_scoring/blob/main/automated_autobiographical_interview_scoring_share.ipynb) by Ruben von Genugten, published on [GitHub](https://github.com/rubenvangenugten/autobiographical_interview_scoring) under the GPL-3.0 licence. It has been modified in order to adapt it to our study and data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pysbd\n",
    "import re\n",
    "from transformers import AutoTokenizer, TFDistilBertForSequenceClassification\n",
    "from transformers import TextClassificationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "marian = pd.read_csv(\"../data/translated/data_marian.csv\")\n",
    "mbart = pd.read_csv(\"../data/translated/data_mbart.csv\")\n",
    "google = pd.read_csv(\"../data/translated/data_google.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at vangenugtenr/autobiographical_interview_scoring.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# access trained model and tokenizer\n",
    "# this model was trained and used by Genugten & Schacter 2024 \n",
    "aiscoring = 'vangenugtenr/autobiographical_interview_scoring'\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained(aiscoring)\n",
    "tokenizer = AutoTokenizer.from_pretrained(aiscoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we create a data frame for each data set with the text data in long format \n",
    "# the long format contains one row per sentence that can then be classified \n",
    "\n",
    "# define sentence segmenter\n",
    "seg = pysbd.Segmenter(language=\"en\", clean=False)\n",
    "\n",
    "# define function \n",
    "def reshape_to_long_format(data):\n",
    "    list_of_dataframes = []\n",
    "    for row in range(data.shape[0]):\n",
    "        # access some general info about this narrative\n",
    "        this_subID = data.iloc[row, data.columns.get_loc(\"ID\")]\n",
    "        narrative = data.iloc[row, data.columns.get_loc(\"text_eng\")]\n",
    "        # store current row\n",
    "        currentRow = data.iloc[[row], :]\n",
    "        # create a new dataframe with each row a new sentence, and subID added\n",
    "        segmented_sentences = seg.segment(narrative)\n",
    "        sentences_df = pd.DataFrame(segmented_sentences, columns=['sentence'])\n",
    "        sentences_df[\"ID\"] = this_subID\n",
    "        # create a new merged dataframe\n",
    "        merged_thisNarrative = pd.merge(currentRow, sentences_df, on=[\"ID\"])\n",
    "        list_of_dataframes.append(merged_thisNarrative)\n",
    "    return pd.concat(list_of_dataframes)\n",
    "\n",
    "# here we process each of our data sets separately using the defined function\n",
    "marian_long = reshape_to_long_format(marian)\n",
    "mbart_long = reshape_to_long_format(mbart)\n",
    "google_long = reshape_to_long_format(google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we prepare the data sets for the model \n",
    "# that means, the data are shaped such, that BERT is able to work with them \n",
    "\n",
    "# define data type, which should be character \n",
    "marian_long.loc[:,'sentence'] = marian_long.loc[:,'sentence'].astype('str')\n",
    "mbart_long.loc[:,'sentence'] = mbart_long.loc[:,'sentence'].astype('str')\n",
    "google_long.loc[:,'sentence'] = google_long.loc[:,'sentence'].astype('str')\n",
    "\n",
    "# define a function \n",
    "def prepare(data):\n",
    "    test_texts = []\n",
    "    # extract each sentence, convert to string, and append to list\n",
    "    for row in range(data.shape[0]):\n",
    "        temp_text = data.iloc[row, data.columns.get_loc(\"sentence\")]\n",
    "        temp_text = str(temp_text)  \n",
    "        test_texts.append(temp_text)\n",
    "    # encode text for BERT model\n",
    "    encodings = tokenizer(test_texts, truncation=True, padding=True)\n",
    "    # convert to a TensorFlow dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(encodings)))\n",
    "    return dataset, test_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\annik\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# here we classify the sentences \n",
    "\n",
    "# set up text classification pipeline using the defined model and tokenizer\n",
    "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=True)\n",
    "\n",
    "def classification(data):\n",
    "    # use the preparation function from above \n",
    "    dataset, test_texts = prepare(data)\n",
    "    # Split classification up into batches of sentences to manage RAM\n",
    "    stored_test = []\n",
    "    batch_size = 200\n",
    "    # unse the classification pipeline \n",
    "    for i in range(0, len(test_texts), batch_size):\n",
    "      stored_test.extend(pipe(test_texts[i:i+batch_size]))\n",
    "    return stored_test\n",
    "\n",
    "# here we process our data sets using the function\n",
    "marian_classified = classification(marian_long)\n",
    "mbart_classified = classification(mbart_long)\n",
    "google_classified = classification(google_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we generate new dataframes with predictions \n",
    "\n",
    "def predictions(data, stored_test):\n",
    "    # create a list to store prediction dataframes\n",
    "    list_of_predictionDfs = []\n",
    "    # For each item in the stored_test (predictions), create a data frame and process\n",
    "    for row in range(len(stored_test)):\n",
    "        thisTestLabels = pd.DataFrame(stored_test[row])\n",
    "        # set the 'label' as the index and remove it from the columns\n",
    "        thisTestLabels.index = thisTestLabels['label']\n",
    "        thisTestLabels = thisTestLabels.drop('label', axis=1)\n",
    "        thisTestLabels = thisTestLabels.transpose()\n",
    "        # append the data frame to the list\n",
    "        list_of_predictionDfs.append(thisTestLabels)\n",
    "    # get the prediction data frames \n",
    "    predictionsDf = pd.concat(list_of_predictionDfs)\n",
    "    # identify the most likely label for each sentence\n",
    "    predictionsDf['toplabel'] = predictionsDf.idxmax(axis=1)\n",
    "    # merge the predictions with the original data frame \n",
    "    merged_data = pd.concat([data.reset_index(drop=True), predictionsDf.reset_index(drop=True)], axis=1)\n",
    "    # add a variable with a word count for each sentence\n",
    "    merged_data['sentenceWordCount'] = merged_data['sentence'].apply(lambda x: len(re.findall(r'\\w+', str(x))))\n",
    "    return merged_data\n",
    "\n",
    "marian_predictions = predictions(marian_long, marian_classified)\n",
    "mbart_predictions = predictions(mbart_long, mbart_classified)\n",
    "google_predictions = predictions(google_long, google_classified)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>text_eng</th>\n",
       "      <th>sentence</th>\n",
       "      <th>LABEL_0</th>\n",
       "      <th>LABEL_1</th>\n",
       "      <th>LABEL_2</th>\n",
       "      <th>LABEL_3</th>\n",
       "      <th>toplabel</th>\n",
       "      <th>sentenceWordCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>Als 7-jähriger Bin ich einmal 7-8 meter hohen ...</td>\n",
       "      <td>As a 7-year-old I once climbed 7-8 meters high...</td>\n",
       "      <td>As a 7-year-old I once climbed 7-8 meters high...</td>\n",
       "      <td>0.008462</td>\n",
       "      <td>0.005004</td>\n",
       "      <td>0.980545</td>\n",
       "      <td>0.005990</td>\n",
       "      <td>LABEL_2</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>Als 7-jähriger Bin ich einmal 7-8 meter hohen ...</td>\n",
       "      <td>As a 7-year-old I once climbed 7-8 meters high...</td>\n",
       "      <td>Then fell down unharmed, as the branches all a...</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.995208</td>\n",
       "      <td>LABEL_3</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>als ich 4 oder 5 war, war ich mit meinem Hund ...</td>\n",
       "      <td>When I was 4 or 5, I was walking with my dog (...</td>\n",
       "      <td>When I was 4 or 5, I was walking with my dog (...</td>\n",
       "      <td>0.027041</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.041447</td>\n",
       "      <td>0.930364</td>\n",
       "      <td>LABEL_3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102</td>\n",
       "      <td>als ich 4 oder 5 war, war ich mit meinem Hund ...</td>\n",
       "      <td>When I was 4 or 5, I was walking with my dog (...</td>\n",
       "      <td>It was in the evening and the sun just went do...</td>\n",
       "      <td>0.005022</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.994370</td>\n",
       "      <td>LABEL_3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>als ich 4 oder 5 war, war ich mit meinem Hund ...</td>\n",
       "      <td>When I was 4 or 5, I was walking with my dog (...</td>\n",
       "      <td>After that I came back and my beloved hangover...</td>\n",
       "      <td>0.009316</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.990039</td>\n",
       "      <td>LABEL_3</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID                                               text  \\\n",
       "0  101  Als 7-jähriger Bin ich einmal 7-8 meter hohen ...   \n",
       "1  101  Als 7-jähriger Bin ich einmal 7-8 meter hohen ...   \n",
       "2  102  als ich 4 oder 5 war, war ich mit meinem Hund ...   \n",
       "3  102  als ich 4 oder 5 war, war ich mit meinem Hund ...   \n",
       "4  102  als ich 4 oder 5 war, war ich mit meinem Hund ...   \n",
       "\n",
       "                                            text_eng  \\\n",
       "0  As a 7-year-old I once climbed 7-8 meters high...   \n",
       "1  As a 7-year-old I once climbed 7-8 meters high...   \n",
       "2  When I was 4 or 5, I was walking with my dog (...   \n",
       "3  When I was 4 or 5, I was walking with my dog (...   \n",
       "4  When I was 4 or 5, I was walking with my dog (...   \n",
       "\n",
       "                                            sentence   LABEL_0   LABEL_1  \\\n",
       "0  As a 7-year-old I once climbed 7-8 meters high...  0.008462  0.005004   \n",
       "1  Then fell down unharmed, as the branches all a...  0.004054  0.000297   \n",
       "2  When I was 4 or 5, I was walking with my dog (...  0.027041  0.001147   \n",
       "3  It was in the evening and the sun just went do...  0.005022  0.000292   \n",
       "4  After that I came back and my beloved hangover...  0.009316  0.000185   \n",
       "\n",
       "    LABEL_2   LABEL_3 toplabel  sentenceWordCount  \n",
       "0  0.980545  0.005990  LABEL_2                 22  \n",
       "1  0.000441  0.995208  LABEL_3                 25  \n",
       "2  0.041447  0.930364  LABEL_3                 18  \n",
       "3  0.000316  0.994370  LABEL_3                 16  \n",
       "4  0.000460  0.990039  LABEL_3                 19  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marian_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we create to variables wit predicted classifications\n",
    "# number of words classified as internal, and number of words classified as external \n",
    "\n",
    "def predicted_words(df):\n",
    "    # create two new columns for the counts\n",
    "    df[['internal_pred']] = 0\n",
    "    df[['external_pred']] = 0\n",
    "    # loop through each row and calculate the counts\n",
    "    for row in range(df.shape[0]):\n",
    "        predictionType_thisIter = df.iloc[row, df.columns.get_loc(\"toplabel\")]\n",
    "        numTotalWords = df.iloc[row, df.columns.get_loc(\"sentenceWordCount\")]\n",
    "        # get the column locations for internal and external predictions\n",
    "        internalLocation = df.columns.get_loc(\"internal_pred\")\n",
    "        externalLocation = df.columns.get_loc(\"external_pred\")\n",
    "        # classify based on the label and update the columns\n",
    "        if predictionType_thisIter == 'LABEL_0':\n",
    "            df.iloc[row, externalLocation] = numTotalWords\n",
    "        elif predictionType_thisIter == 'LABEL_1':\n",
    "            halfDetails = numTotalWords / 2\n",
    "            df.iloc[row, externalLocation] = halfDetails\n",
    "            df.iloc[row, internalLocation] = halfDetails\n",
    "        elif predictionType_thisIter == 'LABEL_2':\n",
    "            df.iloc[row, externalLocation] = numTotalWords / 4\n",
    "            df.iloc[row, internalLocation] = numTotalWords * (3 / 4)\n",
    "        elif predictionType_thisIter == 'LABEL_3':\n",
    "            df.iloc[row, internalLocation] = numTotalWords\n",
    "    return df\n",
    "\n",
    "# here we apply the function to our data frames \n",
    "marian_new = predicted_words(marian_predictions)\n",
    "mbart_new = predicted_words(mbart_predictions)\n",
    "google_new = predicted_words(google_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>text_eng</th>\n",
       "      <th>sentence</th>\n",
       "      <th>LABEL_0</th>\n",
       "      <th>LABEL_1</th>\n",
       "      <th>LABEL_2</th>\n",
       "      <th>LABEL_3</th>\n",
       "      <th>toplabel</th>\n",
       "      <th>sentenceWordCount</th>\n",
       "      <th>internal_pred</th>\n",
       "      <th>external_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>Als 7-jähriger Bin ich einmal 7-8 meter hohen ...</td>\n",
       "      <td>As a 7-year-old I once climbed 7-8 meters high...</td>\n",
       "      <td>As a 7-year-old I once climbed 7-8 meters high...</td>\n",
       "      <td>0.008462</td>\n",
       "      <td>0.005004</td>\n",
       "      <td>0.980545</td>\n",
       "      <td>0.005990</td>\n",
       "      <td>LABEL_2</td>\n",
       "      <td>22</td>\n",
       "      <td>16.5</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>Als 7-jähriger Bin ich einmal 7-8 meter hohen ...</td>\n",
       "      <td>As a 7-year-old I once climbed 7-8 meters high...</td>\n",
       "      <td>Then fell down unharmed, as the branches all a...</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.995208</td>\n",
       "      <td>LABEL_3</td>\n",
       "      <td>25</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>als ich 4 oder 5 war, war ich mit meinem Hund ...</td>\n",
       "      <td>When I was 4 or 5, I was walking with my dog (...</td>\n",
       "      <td>When I was 4 or 5, I was walking with my dog (...</td>\n",
       "      <td>0.027041</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.041447</td>\n",
       "      <td>0.930364</td>\n",
       "      <td>LABEL_3</td>\n",
       "      <td>18</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102</td>\n",
       "      <td>als ich 4 oder 5 war, war ich mit meinem Hund ...</td>\n",
       "      <td>When I was 4 or 5, I was walking with my dog (...</td>\n",
       "      <td>It was in the evening and the sun just went do...</td>\n",
       "      <td>0.005022</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.994370</td>\n",
       "      <td>LABEL_3</td>\n",
       "      <td>16</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>als ich 4 oder 5 war, war ich mit meinem Hund ...</td>\n",
       "      <td>When I was 4 or 5, I was walking with my dog (...</td>\n",
       "      <td>After that I came back and my beloved hangover...</td>\n",
       "      <td>0.009316</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.990039</td>\n",
       "      <td>LABEL_3</td>\n",
       "      <td>19</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID                                               text  \\\n",
       "0  101  Als 7-jähriger Bin ich einmal 7-8 meter hohen ...   \n",
       "1  101  Als 7-jähriger Bin ich einmal 7-8 meter hohen ...   \n",
       "2  102  als ich 4 oder 5 war, war ich mit meinem Hund ...   \n",
       "3  102  als ich 4 oder 5 war, war ich mit meinem Hund ...   \n",
       "4  102  als ich 4 oder 5 war, war ich mit meinem Hund ...   \n",
       "\n",
       "                                            text_eng  \\\n",
       "0  As a 7-year-old I once climbed 7-8 meters high...   \n",
       "1  As a 7-year-old I once climbed 7-8 meters high...   \n",
       "2  When I was 4 or 5, I was walking with my dog (...   \n",
       "3  When I was 4 or 5, I was walking with my dog (...   \n",
       "4  When I was 4 or 5, I was walking with my dog (...   \n",
       "\n",
       "                                            sentence   LABEL_0   LABEL_1  \\\n",
       "0  As a 7-year-old I once climbed 7-8 meters high...  0.008462  0.005004   \n",
       "1  Then fell down unharmed, as the branches all a...  0.004054  0.000297   \n",
       "2  When I was 4 or 5, I was walking with my dog (...  0.027041  0.001147   \n",
       "3  It was in the evening and the sun just went do...  0.005022  0.000292   \n",
       "4  After that I came back and my beloved hangover...  0.009316  0.000185   \n",
       "\n",
       "    LABEL_2   LABEL_3 toplabel  sentenceWordCount  internal_pred  \\\n",
       "0  0.980545  0.005990  LABEL_2                 22           16.5   \n",
       "1  0.000441  0.995208  LABEL_3                 25           25.0   \n",
       "2  0.041447  0.930364  LABEL_3                 18           18.0   \n",
       "3  0.000316  0.994370  LABEL_3                 16           16.0   \n",
       "4  0.000460  0.990039  LABEL_3                 19           19.0   \n",
       "\n",
       "   external_pred  \n",
       "0            5.5  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marian_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum up internal and external words for each narrative\n",
    "# because right now we are still on sentence level\n",
    "\n",
    "def sum_narrative(df):\n",
    "    # select the relevant columns for output\n",
    "    df_write_out_subset = df.loc[:, [\"ID\", \"internal_pred\", \"external_pred\", 'sentenceWordCount']]\n",
    "    # Group by ID, then sum the 'internal_pred' and 'external_pred' columns\n",
    "    grouped = df_write_out_subset.groupby(by=[\"ID\"]).agg({\n",
    "        'internal_pred': 'sum',\n",
    "        'external_pred': 'sum',\n",
    "        'sentenceWordCount': 'sum'\n",
    "    }).reset_index()  # reset index to get a clean dataframe\n",
    "    grouped.rename(columns={\"sentenceWordCount\": \"total_words\"}, inplace=True)\n",
    "    return grouped\n",
    "\n",
    "# here we apply the function to our data frames \n",
    "marian_grouped = sum_narrative(marian_new)\n",
    "mbart_grouped = sum_narrative(mbart_new)\n",
    "google_grouped = sum_narrative(google_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write data sets into csv files\n",
    "marian_grouped.to_csv('../data/scored/marian_scored.csv', index=False)\n",
    "mbart_grouped.to_csv('../data/scored/mbart_scored.csv', index=False)\n",
    "google_grouped.to_csv('../data/scored/google_scored.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
