{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Translation\n",
    "\n",
    "The following code is employed for the purpose of automatically translating our German text data into English, utilising natural language processing. We are employing three different models for this task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Housekeeping\n",
    "\n",
    "Here, we import the data and packages that we need for the translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "from deep_translator import GoogleTranslator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data \n",
    "data = pd.read_csv(\"../data/raw/test_data.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MarianMT\n",
    "\n",
    "Translation with the model MarianMT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model that is used for translation\n",
    "marian = \"Helsinki-NLP/opus-mt-de-en\"\n",
    "model = MarianMTModel.from_pretrained(marian)\n",
    "tokenizer = MarianTokenizer.from_pretrained(marian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to tranlate text data\n",
    "def translate_marian(text):\n",
    "    # tokenize the text input \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    # generate translation \n",
    "    translated_tokens = model.generate(**inputs)\n",
    "    # decode the translated tokens into string\n",
    "    translated_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the translation function to the \"text\" column\n",
    "data['text_eng'] = data['text'].apply(translate_marian)\n",
    "\n",
    "# write data into a file \n",
    "data.to_csv(\"../data/translated/marian.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MBart\n",
    "\n",
    "Translation with the model MBart: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model that is used for translation\n",
    "mbart = \"facebook/mbart-large-50-many-to-many-mmt\"\n",
    "model = MBartForConditionalGeneration.from_pretrained(mbart)\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(mbart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to tranlate text data\n",
    "def translate_mbart(text):\n",
    "    tokenizer.src_lang = \"de_DE\"  \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    translated_tokens = model.generate(**inputs, forced_bos_token_id=tokenizer.lang_code_to_id[\"en_XX\"])\n",
    "    translated_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the translation function \n",
    "data['text_eng'] = data['text'].apply(translate_mbart)\n",
    "\n",
    "# write data into a file\n",
    "data.to_csv(\"../data/translated/mbart.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Translator\n",
    "\n",
    "Translation with Google Translator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to translate text data\n",
    "def translate_google(text):\n",
    "    translated = GoogleTranslator(source='de', target='en').translate(text)\n",
    "    return translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the translation function \n",
    "data['text_eng'] = data['text'].apply(translate_google)\n",
    "\n",
    "# write data into a file\n",
    "data.to_csv(\"../data/translated/google.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
