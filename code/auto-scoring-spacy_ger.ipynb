{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring MTT details using BabelNet and spaCy\n",
    "\n",
    "Here, I am developing code to detect mental time travel markers in texts using SpaCy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "from spacy.matcher import Matcher\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv(\"../data/raw/test_data.csv\")\n",
    "\n",
    "# add new ID \n",
    "data[\"ID_new\"] = data[\"ResponseId\"].astype(str) + \"_\" + data[\"trial\"].astype(str)\n",
    "\n",
    "# create dataframe with relevant variables\n",
    "selected = ['ID_new', 'text']  \n",
    "data = data[selected]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Note, that you have to create a [BabelNet](https://babelnet.org/) account to get an API key. Insert the API key from your account into the following code snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication for BabelNet \n",
    "# define API key \n",
    "API_KEY = \"YOUR_API_KEY\"\n",
    "# url\n",
    "BASE_URL = \"https://babelnet.io/v9/\"\n",
    "# headers\n",
    "HEADERS   = {\"Accept-Encoding\": \"gzip\"}\n",
    "# language: German\n",
    "LANG = \"DE\"\n",
    "# Cache to reduce API calls\n",
    "sense_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load language model from spacy\n",
    "nlp = spacy.load(\"de_core_news_lg\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for creating dictionaries related to emotion and perception words\n",
    " \n",
    "# API call to get babelnet synsets\n",
    "def get_babelnet_senses(word, lang=LANG):\n",
    "    if word in sense_cache:\n",
    "        return sense_cache[word]\n",
    "\n",
    "    url    = BASE_URL + \"getSenses\"\n",
    "    params = {\"lemma\": word, \"searchLang\": lang, \"key\": API_KEY}\n",
    "    resp   = requests.get(url, params=params, headers=HEADERS)\n",
    "    time.sleep(1)\n",
    "    if resp.status_code != 200:\n",
    "        print(f\"Fehler bei '{word}': {resp.status_code} – {resp.text[:100]!r}\")\n",
    "        return []\n",
    "    senses = resp.json()\n",
    "    sense_cache[word] = senses\n",
    "    return senses\n",
    "\n",
    "# fumction to extract lemmas\n",
    "def extract_lemma_from_sense(sense, lang=LANG, allowed_pos={\"NOUN\", \"ADJ\", \"VERB\"}):\n",
    "    props = sense.get(\"properties\", {})\n",
    "    lemma = props.get(\"fullLemma\", \"\").lower()\n",
    "    if props.get(\"language\") == lang and props.get(\"pos\") in allowed_pos:\n",
    "        if not re.search(r\"[0-9()@#\\[\\]{}:;,\\-`´—]+\", lemma) and not re.search(r'[\\U00010000-\\U0010ffff]', lemma):\n",
    "            return {lemma}\n",
    "    return set()\n",
    "\n",
    "# function to get the lemmas from babelnet\n",
    "def get_babelnet_lemmas(seed_words):\n",
    "    all_lemmas = set()\n",
    "    for w in seed_words:\n",
    "        senses = get_babelnet_senses(w)\n",
    "        print(f\"{len(senses)} Senses für '{w}' gefunden\")\n",
    "        for sense in senses:\n",
    "            all_lemmas |= extract_lemma_from_sense(sense)\n",
    "    print(f\"  ⇒ insgesamt {len(all_lemmas)} Lemmas\")\n",
    "    return all_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of perception words\n",
    "\n",
    "# German words for base emotions and thoughts \n",
    "emotion_seeds = {\n",
    "    \"Wut\": [\"Wut\", \"Zorn\", \"ärgerlich\", \"verärgert\", \"zornig\"],\n",
    "    \"Freude\": [\"Freude\", \"Glück\", \"fröhlich\", \"zufrieden\", \"glücklich\"],\n",
    "    \"Angst\": [\"Angst\", \"Furcht\", \"ängstlich\"],\n",
    "    \"Traurigkeit\": [\"Traurigkeit\", \"Kummer\", \"unglücklich\", \"traurig\"],\n",
    "    \"Ekel\": [\"Ekel\", \"widerlich\"],\n",
    "    \"Liebe\": [\"Liebe\", \"lieben\"],\n",
    "    \"Hass\": [\"Hass\", \"hassen\", \"Abneigung\"],\n",
    "    \"Stress\": [\"Stress\", \"gestresst\", \"überfordert\", \"unruhig\"],\n",
    "    \"Schuld\": [\"Schuld\", \"schuldig\", \"Reue\", \"bereuen\"],\n",
    "    \"Scham\": [\"Scham\", \"peinlich\", \"beschämt\", \"verlegen\"],\n",
    "    \"Stolz\": [\"Stolz\", \"stolz\", \"selbstbewusst\"],\n",
    "    \"Verzweiflung\": [\"Verzweiflung\", \"hoffnungslos\", \"verlassen\", \"hilflos\"],\n",
    "    \"Gedanken\": [\"Gedanke\", \"denken\", \"vermuten\", \"hoffen\", \"glauben\"]\n",
    "}\n",
    "\n",
    "# German words for perceptions \n",
    "perception_seeds = {\n",
    "    \"Wahrnehmung\": [\"Wahrnehmung\", \"wahrnehmen\", \"Empfindung\", \"empfinden\"],\n",
    "    \"Sehen\": [\"sehen\", \"Anblick\", \"Aussicht\", \"anschauen\", \"hell\", \"dunkel\", \"bunt\", \"rot\", \"blau\", \"grün\", \"gelb\", \"orange\", \"lila\"],\n",
    "    \"Hören\": [\"hören\", \"Geräusch\", \"Lärm\", \"Musik\", \"laut\", \"leise\"],\n",
    "    \"Tasten\": [\"fühlen\", \"berühren\", \"tasten\", \"taktil\", \"weich\", \"hart\", \"glatt\", \"rau\"],\n",
    "    \"Riechen\": [\"riechen\", \"Geruch\"],\n",
    "    \"Schmecken\": [\"schmecken\", \"Geschmack\", \"salzig\", \"süß\", \"bitter\", \"würzig\"],\n",
    "    \"Temperatur\": [\"Temperatur\", \"Hitze\", \"Kälte\", \"kalt\", \"warm\", \"heiß\"],\n",
    "    \"Körperwahrnehmung\": [\"Schmerz\", \"schmerzen\", \"Hunger\", \"hungrig\", \"Durst\", \"durstig\", \"Müdigkeit\", \"müde\"],\n",
    "}\n",
    "\n",
    "# function to build dictionary \n",
    "def build_lemma_dict(seed_dict):\n",
    "    result = {}\n",
    "    for category, seed_words in seed_dict.items():\n",
    "        lemmas = get_babelnet_lemmas(seed_words)\n",
    "        result[category] = list(lemmas)\n",
    "    return result\n",
    "\n",
    "# dictionary for emotions\n",
    "emotion_dict = build_lemma_dict(emotion_seeds)\n",
    "\n",
    "# dictionary for perceptions\n",
    "perception_dict = build_lemma_dict(perception_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to define spacy matcher\n",
    "def build_matcher(nlp, category_dict, label_prefix):\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    for category, lemmas in category_dict.items():\n",
    "        for lemma in lemmas:\n",
    "            pattern = [{\"LEMMA\": lemma}]\n",
    "            matcher.add(f\"{label_prefix}_{category}\", [pattern])\n",
    "    return matcher\n",
    "\n",
    "# matcher for emotion words \n",
    "emotion_matcher = build_matcher(nlp, emotion_dict, \"EMOTION\")\n",
    "\n",
    "# matcher for perception words \n",
    "perception_matcher = build_matcher(nlp, perception_dict, \"PERCEPTION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to find time markers\n",
    "\n",
    "# define time markers\n",
    "monate = r\"(Januar|Februar|März|April|Mai|Juni|Juli|August|September|Oktober|November|Dezember)\"\n",
    "wochentage = r\"(Montag|Dienstag|Mittwoch|Donnerstag|Freitag|Samstag|Sonntag)\"\n",
    "holidays = r\"(Weihnachten|Heiligabend|Ostern|Neujahr|Pfingsten|Silvester|Karfreitag)\"\n",
    "tageszeiten = r\"\\b(Frühjahr|abends|Morgen|morgens|Mittag|mittags|Nacht|nachts|Nachmittag|nachmittags|Vormittag|vormittags)\\b\"\n",
    "zeiten = r\"\\b(heute|gestern|morgen|vorgestern|übermorgen|Wochenende|Woche|Monat|Jahr)\\b\"\n",
    "jahreszeiten = r\"\\b(Frühling|Frühjahr|Sommer|Herbst|Winter)\\b\"\n",
    "# define date patterns using regex\n",
    "date_patterns = [\n",
    "    r\"\\b\\d{1,2}\\.\\d{1,2}\\.\\d{2,4}\\b\",           \n",
    "    r\"\\b\\d{1,2}\\.?\\s+\" + monate + r\"\\s+\\d{4}\",  \n",
    "    r\"\\b\\d{4}\\b\",                                        \n",
    "    r\"\\bum\\s+\\d{1,2}(:\\d{2})?\\s*Uhr\", \n",
    "    r\"\\b(Am\\s+\\d{1,2}\\.\\s+\" + monate + r\")\\b\",\n",
    "    r\"\\bam\\s+(\\d{1,2})\\b\", \n",
    "    wochentage,  \n",
    "    monate, \n",
    "    holidays, \n",
    "    tageszeiten,\n",
    "    zeiten,\n",
    "    jahreszeiten      \n",
    "]\n",
    "\n",
    "# function to extract time markers\n",
    "def extract_time_info(text, doc):\n",
    "    times = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in [\"DATE\", \"TIME\"]:\n",
    "            times.append(ent.text)\n",
    "    for pattern in date_patterns:\n",
    "        matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "        if matches:\n",
    "            if isinstance(matches[0], tuple):\n",
    "                times.extend([m[0] for m in matches])  \n",
    "            else:\n",
    "                times.extend(matches)\n",
    "    times = [time for time in times]\n",
    "    return times "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function for text analysis \n",
    "def analyze_text(text):\n",
    "    doc = nlp(text)\n",
    "    # Lemmatize tokens\n",
    "    lemmatized_tokens = [token.lemma_ for token in doc]\n",
    "    emotion_matches = emotion_matcher(doc)\n",
    "    perception_matches = perception_matcher(doc)\n",
    "    # Extracting elements\n",
    "    events = [token.lemma_ for token in doc if token.dep_ == \"ROOT\" and token.pos_ == \"VERB\"]\n",
    "    places = [(ent.text, ent.label_) for ent in doc.ents if ent.label_ in [\"GPE\", \"LOC\", \"FAC\"]]\n",
    "    times = extract_time_info(text, doc)\n",
    "    emotions = [nlp.vocab.strings[match_id].replace(\"EMOTION_\", \"\") for match_id, _, _ in emotion_matches]\n",
    "    perceptions = [nlp.vocab.strings[match_id].replace(\"PERCEPTION_\", \"\") for match_id, _, _ in perception_matches]\n",
    "    if not places and not times and not emotions and not perceptions:\n",
    "        events = []\n",
    "    return events, places, times, emotions, perceptions\n",
    "\n",
    "# Apply functions to each row \n",
    "results = data['text'].apply(analyze_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert results to separate columns\n",
    "results_df = pd.DataFrame(results.tolist(), columns=['events', 'places', 'times', 'emotions', 'perceptions'])\n",
    "\n",
    "# count the occurences\n",
    "results_df['event_count'] = results_df['events'].apply(len)\n",
    "results_df['place_count'] = results_df['places'].apply(len)\n",
    "results_df['time_count'] = results_df['times'].apply(len)\n",
    "results_df['emotion_count'] = results_df['emotions'].apply(len)\n",
    "results_df['perception_count'] = results_df['perceptions'].apply(len)\n",
    "\n",
    "# add the counts to the original data frame\n",
    "cols_to_add = ['event_count', 'place_count', 'time_count', 'emotion_count', 'perception_count']\n",
    "for col in cols_to_add:\n",
    "    data[col] = results_df[col]\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data in new csv file\n",
    "data.to_csv('../data/scored/spacy_scored.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
